{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fa8a49-293f-480a-9919-93ab3a87968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.stats.qmc as qmc\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning) # for RuntimeWarning only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c38c9b0-e9ad-4d8e-9e53-a4c1fdc70a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_INP_data(filename, conc_suffix):\n",
    "    \n",
    "    data = pd.read_csv(filename,index_col='temp_bin')\n",
    "    # If you want to mask any of the data to remove particular runs, you need to add this here.\n",
    "    # It is easy to filter so that you only get columns that e.g. contain \"CAO\" or have\n",
    "    # heights > 2000m if they're in the column name.\n",
    "    if conc_suffix == '_NT':\n",
    "        err_suffix = '_err'\n",
    "    else:\n",
    "        err_suffix = conc_suffix+'_err'\n",
    "    raw_concs = data[data.columns[pd.Series(data.columns).str.endswith(conc_suffix)]]\n",
    "    raw_concs.columns = raw_concs.columns.str.replace(conc_suffix,'')\n",
    "    logged_concs = np.log(raw_concs)\n",
    "\n",
    "\n",
    "    raw_errors = data[data.columns[pd.Series(data.columns).str.endswith(err_suffix)]]\n",
    "    raw_errors.columns = raw_errors.columns.str.replace(err_suffix,'')\n",
    "    temps = logged_concs.index.values\n",
    "    return temps, raw_concs, logged_concs, raw_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5e0c3e-5bc5-4467-be88-83a85076a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_param_fit(T, ln_nu, T_max, a, b):\n",
    "    # Apply the fit to an array of temperatures T\n",
    "    return ln_nu + a*(T_max-T)**b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f4d8dd-60e0-4ee8-b221-6174936008bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_nans(*args):\n",
    "    # Strip nans from multiple inputs where NaN values have the same indices in each input.\n",
    "    nan_mask = np.logical_not(np.isnan(args[0]))\n",
    "    nanless = []\n",
    "    for a in args:\n",
    "        nanless.append(a[nan_mask])\n",
    "    return nanless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bce57f-7679-427c-888a-b6db2651c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_chi_squared_test(p, temps, log_concs, weighted_error):\n",
    "    # Perform reduced chi-squared test for fit parameters p\n",
    "    modelled = four_param_fit(temps, *p) #*p unlocks the list p so this is like writing temps, p[0], p[1]...\n",
    "    residual = log_concs - modelled\n",
    "    chi_sq = np.sum((residual/weighted_error)**2)\n",
    "    red_chi_sq = chi_sq/(len(log_concs)-len(p))\n",
    "    return red_chi_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8aca30-0d1b-4c6e-9829-71eda1b10ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4-dimensional latin hypercube object. Seed chosen for replication of results.\n",
    "lhc = qmc.LatinHypercube(4, seed=280299)\n",
    "# Take 100 LH samples\n",
    "samples = lhc.random(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79177bc0-b66b-4a0a-8658-8eb53b0b1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounded_and_sampled_scipy_4_param(temps, logged_concs, raw_concs, raw_errors, samples, run_id,\n",
    "                                      nu_range=(-6,-2), plot=False, silent=True):\n",
    "    \"\"\"\n",
    "    Ugly but functional function to find potential best-fits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    temps: ndarray\n",
    "        Temperature bins\n",
    "    logged_concs: pandas DataFrame\n",
    "        concentrations with a natural logarithm applied\n",
    "    raw_concs: pandas DataFrame\n",
    "        concentrations\n",
    "    raw_errors: pandas DataFrame\n",
    "        errors\n",
    "    samples: qmc Object\n",
    "        samples chosen in hypercube space\n",
    "    run_id: string\n",
    "        identifier of the run\n",
    "    nu_range: 2-tuple\n",
    "        (lowest possible nu value, highest possible nu value)\n",
    "    plot: boolean\n",
    "        not yet implemented\n",
    "    silent: boolean\n",
    "        say when convergence fails (likely to happen often among the 100 samples)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas\n",
    "        all derived parameters for the run that converged\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataframe to hold parameters for the run                                      \n",
    "    run_params = pd.DataFrame(columns=['nu','T_max','a','b','X2','cov'])\n",
    "    # Strip nans where appropriate as curve_fit doesn't handle them\n",
    "    nanless_concs, nanless_raw, nanless_errs, nanless_temps = strip_nans(\n",
    "                                                        logged_concs[run_id].values,\n",
    "                                                        raw_concs[run_id].values,\n",
    "                                                        raw_errors[run_id].values,\n",
    "                                                        temps\n",
    "    )\n",
    "    # Weight errors in logarithmic space\n",
    "    nanless_weights = nanless_errs/nanless_raw\n",
    "\n",
    "    # Set bounds of the sample space\n",
    "    lower_bounds = [nu_range[0], max(nanless_temps)-2, 0.3, 0.5]\n",
    "    upper_bounds = [nu_range[1], max(nanless_temps)+2, 1.05, 1.0]\n",
    "\n",
    "    # Apply the LH samples to the sample space\n",
    "    scaled = qmc.scale(samples, lower_bounds, upper_bounds)\n",
    "\n",
    "    # Loop through all of the samples and attempt to find a best-fit\n",
    "    for ps in scaled:\n",
    "        try:\n",
    "            p, c = opt.curve_fit(four_param_fit, nanless_temps, nanless_concs, p0=ps,\n",
    "                sigma=nanless_weights, bounds=(lower_bounds,upper_bounds), maxfev=20000)\n",
    "            # Calculate goodness of fit parameter\n",
    "            X2 = reduced_chi_squared_test(p, nanless_temps, nanless_concs, nanless_weights)\n",
    "            # Store in the in the dataframe\n",
    "            run_params.loc[len(run_params)] = [p[0], p[1], p[2], p[3], X2, c]\n",
    "        except:\n",
    "            # Do not fail if convergence can't be found.\n",
    "            if not silent:\n",
    "                print('Failed to converge with parameters', ps)\n",
    "    return run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005b3c82-19a5-4acd-91ee-8d31bfff4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_df(temps, logged_concs, raw_concs, raw_errors, samples, nu_range=(-6,-2)):\n",
    "    \"\"\"\n",
    "    Get a dataframe with the parameters that have the lowest reduced chi-squared for each run.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    temps: ndarray\n",
    "        Temperature bins\n",
    "    logged_concs: pandas DataFrame\n",
    "        concentrations with a natural logarithm applied\n",
    "    raw_concs: pandas DataFrame\n",
    "        concentrations\n",
    "    raw_errors: pandas DataFrame\n",
    "        errors\n",
    "    samples: qmc Object\n",
    "        samples chosen in hypercube space\n",
    "    nu_range: 2-tuple\n",
    "        (lowest possible nu value, highest possible nu value)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas Dataframe\n",
    "        best parameters for each run\n",
    "    \"\"\"\n",
    "    bounded_params = {}\n",
    "    for run in logged_concs:\n",
    "        # Loop through every run to get all parameters and add to dictionary\n",
    "        bounded_params[run] = bounded_and_sampled_scipy_4_param(temps, logged_concs, raw_concs,\n",
    "                                                                raw_errors, samples, run, nu_range)\n",
    "\n",
    "    # create an empty dataframe to store the lowest X2 values\n",
    "    lowest_X2_bounded_df = pd.DataFrame(columns=['nu','T_max','a','b','X2','cov'])\n",
    "\n",
    "    # loop through the dictionary and find the lowest X2 value for each run\n",
    "    for run_id, df in bounded_params.items():\n",
    "        df = df.dropna()\n",
    "        if df.empty:\n",
    "            # create a new row with NaN values and concatenate it to lowest_X2_df\n",
    "            lowest_X2_bounded_row = pd.DataFrame([[np.nan]*len(lowest_X2_bounded_df.columns)], \n",
    "                                        columns=lowest_X2_bounded_df.columns, \n",
    "                                        index=[run_id])\n",
    "            lowest_X2_bounded_df = pd.concat([lowest_X2_bounded_df, lowest_X2_bounded_row])\n",
    "        else:\n",
    "            lowest_X2_bounded_row = df.nsmallest(1, 'X2')\n",
    "            lowest_X2_bounded_row.index = [run_id]\n",
    "            lowest_X2_bounded_df = pd.concat([lowest_X2_bounded_df, lowest_X2_bounded_row])\n",
    "\n",
    "    return lowest_X2_bounded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48735d5c-5537-4d9e-b0ec-068618ae4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/home/users/erinraif/acao_data/inp_data/'\n",
    "suffixes = ['_NT', '_nN', '_nS', '_nV']\n",
    "INP_concs = 'subtracted_backgrounds_v4_2ul.csv'\n",
    "nX_vals = 'nX_calibrated_v3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445bfca8-e713-4810-bd90-b3cf288c508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [INP_concs, nX_vals, nX_vals, nX_vals]\n",
    "nu_range = [(-6,-2), (-18,-13), (12, 17), (25,33)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1aa244-c01b-472e-9206-0be08bdc3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = {}\n",
    "for s, csv, nus in zip(suffixes, files, nu_range):\n",
    "    temps, raw_concs, logged_concs, raw_errors = read_INP_data(base+csv, s)\n",
    "    params = get_parameter_df(temps, logged_concs, raw_concs, raw_errors, samples, nus)\n",
    "    params_df[s[1:]] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4daaa189-8833-4302-b057-64efdd96839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df['n_INP'] = params_df.pop('NT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc14e55c-1d1f-479f-bb44-d0ba45c9d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_with_suffixes = []\n",
    "\n",
    "# Loop through the dictionary and add suffixes to the columns\n",
    "for key, df in params_df.items():\n",
    "    df = df.add_suffix(f'_{key}')\n",
    "    dfs_with_suffixes.append(df)\n",
    "\n",
    "export_params = pd.concat(dfs_with_suffixes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a05fc0d-b827-491e-bcaf-dca772923be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_params.index.name = 'unique_ID'\n",
    "export_params = export_params.loc[:, ~export_params.columns.str.contains('X2|cov')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d15cc008-9036-4fad-9ca1-703409abdb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_params.to_csv('/home/users/erinraif/acao_data/metadata/parametrisations_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b644e0-7166-45aa-b17c-b93b8b3854b7",
   "metadata": {},
   "source": [
    "## Median INP and nS parametrisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b4481f7-111f-40b5-ae55-1e7d7edcf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_4_param(temps, logged_concs, raw_concs, samples, run_id,\n",
    "                                      nu_range=(-6,-2), plot=False, silent=True):\n",
    "    \"\"\"\n",
    "    Ugly but functional function to find potential best-fits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    temps: ndarray\n",
    "        Temperature bins\n",
    "    logged_concs: pandas DataFrame\n",
    "        concentrations with a natural logarithm applied\n",
    "    raw_concs: pandas DataFrame\n",
    "        concentrations\n",
    "    raw_errors: pandas DataFrame\n",
    "        errors\n",
    "    samples: qmc Object\n",
    "        samples chosen in hypercube space\n",
    "    run_id: string\n",
    "        identifier of the run\n",
    "    nu_range: 2-tuple\n",
    "        (lowest possible nu value, highest possible nu value)\n",
    "    plot: boolean\n",
    "        not yet implemented\n",
    "    silent: boolean\n",
    "        say when convergence fails (likely to happen often among the 100 samples)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas\n",
    "        all derived parameters for the run that converged\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataframe to hold parameters for the run                                      \n",
    "    run_params = pd.DataFrame(columns=['nu','T_max','a','b','X2','cov'])\n",
    "    lower_bounds = [nu_range[0], -9, 0.3, 0.5]\n",
    "    upper_bounds = [nu_range[1], -5, 1.4, 1.0]\n",
    "\n",
    "    # Apply the LH samples to the sample space\n",
    "    scaled = qmc.scale(samples, lower_bounds, upper_bounds)\n",
    "\n",
    "    # Loop through all of the samples and attempt to find a best-fit\n",
    "    for ps in scaled:\n",
    "        try:\n",
    "            p, c = opt.curve_fit(four_param_fit, temps, logged_concs, p0=ps,\n",
    "                bounds=(lower_bounds,upper_bounds), maxfev=20000)\n",
    "            # Calculate goodness of fit parameter\n",
    "            X2 = reduced_chi_squared_test(p, temps, logged_concs, np.ones(len(logged_concs)))\n",
    "            # Store in the in the dataframe\n",
    "            run_params.loc[len(run_params)] = [p[0], p[1], p[2], p[3], X2, c]\n",
    "        except:\n",
    "            # Do not fail if convergence can't be found.\n",
    "            if not silent:\n",
    "                print('Failed to converge with parameters', ps)\n",
    "    return run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "154ea191-5200-429c-a078-7d95cce57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps, raw_concs, logged_concs, raw_errors = read_INP_data(base+INP_concs, '_NT')\n",
    "med_lc = logged_concs.median(axis=1)\n",
    "med_rc = raw_concs.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7104066b-61ad-4853-9693-76e7947076c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_params = median_4_param(temps[(temps < -6) & (temps > -25)], med_lc[(temps < -6) & (temps > -25)], med_rc[(temps < -6) & (temps > -25)], samples, 'median')\n",
    "min_row_index = median_params['X2'].idxmin()\n",
    "\n",
    "# Now you can access the entire row using iloc\n",
    "min_row = median_params.iloc[min_row_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94e10adc-338e-41a2-96ca-973cb49aed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nu                                               -4.212565\n",
       "T_max                                            -6.955521\n",
       "a                                                 1.271137\n",
       "b                                                      0.5\n",
       "X2                                                0.030058\n",
       "cov      [[0.831195751090417, -0.21035032112416055, -0....\n",
       "Name: 9, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07cb818a-6583-4e9f-94c0-2992765e85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps, raw_concs, logged_concs, raw_errors = read_INP_data(base+nX_vals, '_nS')\n",
    "med_lc = logged_concs.median(axis=1)\n",
    "med_rc = raw_concs.median(axis=1)\n",
    "median_params = median_4_param(temps[(temps < -6) & (temps > -24)], med_lc[(temps < -6) & (temps > -24)], med_rc[(temps < -6) & (temps > -24)], samples, 'median', nu_range=(12, 17))\n",
    "min_row_index = median_params['X2'].idxmin()\n",
    "\n",
    "# Now you can access the entire row using iloc\n",
    "min_row = median_params.iloc[min_row_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a351d9fd-43c2-4771-8e88-db31d00ba141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nu                                               12.767265\n",
       "T_max                                            -6.780545\n",
       "a                                                 1.278689\n",
       "b                                                      0.5\n",
       "X2                                                 0.03396\n",
       "cov      [[2.864196450830608, -1.314195131017727, -1.80...\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1e054-1abb-472d-981d-ff981873ef59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acao_fig_basic",
   "language": "python",
   "name": "acao_fig_basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
